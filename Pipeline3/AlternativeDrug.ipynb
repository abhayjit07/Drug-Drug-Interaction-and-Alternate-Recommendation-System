{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Utilising SMILE Embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhayjitsinghgulati/Desktop/Drug-Drug-Interaction-and-Alternate-Recommendation-System/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import MolToSmiles\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse DrugBank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_drugbank_xml(xml_path):\n",
    "    ns = {'db': 'http://www.drugbank.ca'}  # DrugBank namespace\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    drugs = []\n",
    "\n",
    "    for drug in root.findall('db:drug', ns):\n",
    "        name = drug.find('db:name', ns)\n",
    "        if name is not None:\n",
    "            name = name.text.strip()\n",
    "\n",
    "        # Look for SMILES under <calculated-properties>\n",
    "        smiles = None\n",
    "        properties = drug.find('db:calculated-properties', ns)\n",
    "        if properties is not None:\n",
    "            for prop in properties.findall('db:property', ns):\n",
    "                kind = prop.find('db:kind', ns)\n",
    "                if kind is not None and kind.text == 'SMILES':\n",
    "                    value = prop.find('db:value', ns)\n",
    "                    if value is not None:\n",
    "                        smiles = value.text.strip()\n",
    "                        break\n",
    "\n",
    "        if name and smiles:\n",
    "            drugs.append((name, smiles))\n",
    "\n",
    "    return pd.DataFrame(drugs, columns=['drug_name', 'smiles'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drugs = parse_drugbank_xml(\"../Dataset/full database.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug_name</th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bivalirudin</td>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](CCC(O)=O)NC(=O)[C@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leuprolide</td>\n",
       "      <td>CCNC(=O)[C@@H]1CCCN1C(=O)[C@H](CCCNC(N)=N)NC(=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goserelin</td>\n",
       "      <td>CC(C)C[C@H](NC(=O)[C@@H](COC(C)(C)C)NC(=O)[C@H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gramicidin D</td>\n",
       "      <td>CC(C)C[C@@H](NC(=O)CNC(=O)[C@@H](NC=O)C(C)C)C(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Desmopressin</td>\n",
       "      <td>NC(=O)CC[C@@H]1NC(=O)[C@H](CC2=CC=CC=C2)NC(=O)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      drug_name                                             smiles\n",
       "0   Bivalirudin  CC[C@H](C)[C@H](NC(=O)[C@H](CCC(O)=O)NC(=O)[C@...\n",
       "1    Leuprolide  CCNC(=O)[C@@H]1CCCN1C(=O)[C@H](CCCNC(N)=N)NC(=...\n",
       "2     Goserelin  CC(C)C[C@H](NC(=O)[C@@H](COC(C)(C)C)NC(=O)[C@H...\n",
       "3  Gramicidin D  CC(C)C[C@@H](NC(=O)CNC(=O)[C@@H](NC=O)C(C)C)C(...\n",
       "4  Desmopressin  NC(=O)CC[C@@H]1NC(=O)[C@H](CC2=CC=CC=C2)NC(=O)..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drugs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer + Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "model = RobertaModel.from_pretrained(\"seyonec/ChemBERTa-zinc-base-v1\")\n",
    "model.eval()\n",
    "\n",
    "def canonicalize_smiles(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return MolToSmiles(mol, canonical=True) if mol else None\n",
    "\n",
    "def get_embedding(smiles):\n",
    "    inputs = tokenizer(smiles, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1687/11925 [00:29<03:07, 54.64it/s][12:05:16] Explicit valence for atom # 13 Cl, 5, is greater than permitted\n",
      " 15%|█▍        | 1758/11925 [00:30<02:35, 65.37it/s][12:05:17] SMILES Parse Error: syntax error while parsing: OS(O)(O)C1=CC=C(C=C1)C-1=C2\\C=CC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC=C(C=C1)S(O)(O)O)C1=CC=C(C=C1)S([O-])([O-])[O-])\\C1=CC=C(C=C1)S(O)(O)[O-]\n",
      "[12:05:17] SMILES Parse Error: check for mistakes around position 84:\n",
      "[12:05:17] C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC=C(C=C1)S(O\n",
      "[12:05:17] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[12:05:17] SMILES Parse Error: Failed parsing SMILES 'OS(O)(O)C1=CC=C(C=C1)C-1=C2\\C=CC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC=C(C=C1)S(O)(O)O)C1=CC=C(C=C1)S([O-])([O-])[O-])\\C1=CC=C(C=C1)S(O)(O)[O-]' for input: 'OS(O)(O)C1=CC=C(C=C1)C-1=C2\\C=CC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC=C(C=C1)S(O)(O)O)C1=CC=C(C=C1)S([O-])([O-])[O-])\\C1=CC=C(C=C1)S(O)(O)[O-]'\n",
      " 20%|█▉        | 2382/11925 [00:40<02:33, 62.03it/s][12:05:27] Explicit valence for atom # 19 O, 2, is greater than permitted\n",
      " 31%|███       | 3715/11925 [01:02<02:20, 58.50it/s][12:05:49] Explicit valence for atom # 0 O, 3, is greater than permitted\n",
      " 32%|███▏      | 3854/11925 [01:05<02:03, 65.19it/s][12:05:51] Unusual charge on atom 0 number of radical electrons set to zero\n",
      " 34%|███▍      | 4031/11925 [01:07<02:02, 64.28it/s][12:05:54] Explicit valence for atom # 1 Al, 4, is greater than permitted\n",
      " 38%|███▊      | 4523/11925 [01:15<02:07, 58.21it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (539 > 512). Running this sequence through the model will result in indexing errors\n",
      " 55%|█████▌    | 6585/11925 [01:47<01:26, 61.59it/s][12:06:34] Explicit valence for atom # 13 Be, 4, is greater than permitted\n",
      " 63%|██████▎   | 7536/11925 [02:02<01:09, 62.84it/s][12:06:49] Explicit valence for atom # 84 N, 4, is greater than permitted\n",
      " 67%|██████▋   | 7943/11925 [02:08<01:03, 62.71it/s][12:06:55] SMILES Parse Error: syntax error while parsing: OC1=CC=CC(=C1)C-1=C2\\CCC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\\C1=CC(O)=CC=C1\n",
      "[12:06:55] SMILES Parse Error: check for mistakes around position 76:\n",
      "[12:06:55] C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC(O)=CC=C1)C\n",
      "[12:06:55] ~~~~~~~~~~~~~~~~~~~~^\n",
      "[12:06:55] SMILES Parse Error: Failed parsing SMILES 'OC1=CC=CC(=C1)C-1=C2\\CCC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\\C1=CC(O)=CC=C1' for input: 'OC1=CC=CC(=C1)C-1=C2\\CCC(=N2)\\C(=C2/N\\C(\\C=C2)=C(/C2=N/C(/C=C2)=C(\\C2=CC=C\\-1N2)C1=CC(O)=CC=C1)C1=CC(O)=CC=C1)\\C1=CC(O)=CC=C1'\n",
      " 72%|███████▏  | 8628/11925 [02:19<00:50, 65.91it/s][12:07:05] Explicit valence for atom # 1 Cl, 4, is greater than permitted\n",
      " 91%|█████████ | 10846/11925 [02:53<00:16, 63.69it/s][12:07:40] WARNING: not removing hydrogen atom without neighbors\n",
      "[12:07:40] WARNING: not removing hydrogen atom without neighbors\n",
      " 97%|█████████▋| 11582/11925 [03:05<00:06, 56.10it/s][12:07:52] Explicit valence for atom # 1 B, 6, is greater than permitted\n",
      "100%|██████████| 11925/11925 [03:10<00:00, 62.53it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "valid_names = []\n",
    "\n",
    "for idx, row in tqdm(df_drugs.iterrows(), total=len(df_drugs)):\n",
    "    canon_smiles = canonicalize_smiles(row['smiles'])\n",
    "    if canon_smiles:\n",
    "        try:\n",
    "            emb = get_embedding(canon_smiles)\n",
    "            embeddings.append(emb)\n",
    "            valid_names.append(row['drug_name'])\n",
    "        except Exception as e:\n",
    "            continue  # skip failed ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = embedding_matrix.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 4  # include original drug, remove later\n",
    "\n",
    "results = {}\n",
    "\n",
    "for i in range(len(embedding_matrix)):\n",
    "    _, indices = index.search(embedding_matrix[i].reshape(1, -1), topk)\n",
    "    similar_names = [valid_names[idx] for idx in indices[0] if idx != i]  # exclude self\n",
    "    results[valid_names[i]] = similar_names[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_df = pd.DataFrame([\n",
    "    {'drug': drug, 'alternative_1': alts[0], 'alternative_2': alts[1], 'alternative_3': alts[2]}\n",
    "    for drug, alts in results.items() if len(alts) >= 3\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drug</th>\n",
       "      <th>alternative_1</th>\n",
       "      <th>alternative_2</th>\n",
       "      <th>alternative_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bivalirudin</td>\n",
       "      <td>Semaglutide</td>\n",
       "      <td>Avexitide</td>\n",
       "      <td>PP-F11N lutetium Lu-177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leuprolide</td>\n",
       "      <td>Buserelin</td>\n",
       "      <td>Deslorelin</td>\n",
       "      <td>Nerofe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goserelin</td>\n",
       "      <td>Nafarelin</td>\n",
       "      <td>Triptorelin</td>\n",
       "      <td>Ganirelix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gramicidin D</td>\n",
       "      <td>Nerofe</td>\n",
       "      <td>Echinomycin</td>\n",
       "      <td>Reltecimod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Desmopressin</td>\n",
       "      <td>Lypressin</td>\n",
       "      <td>Selepressin</td>\n",
       "      <td>Ozarelix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11908</th>\n",
       "      <td>Alogabat</td>\n",
       "      <td>4-(6-CYCLOHEXYLMETHOXY-9H-PURIN-2-YLAMINO)--BE...</td>\n",
       "      <td>Mizolastine</td>\n",
       "      <td>N-cyclopropyl-4-methyl-3-{2-[(2-morpholin-4-yl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11909</th>\n",
       "      <td>Ropsacitinib</td>\n",
       "      <td>Regadenoson</td>\n",
       "      <td>Vistusertib</td>\n",
       "      <td>Golidocitinib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11910</th>\n",
       "      <td>taletrectinib</td>\n",
       "      <td>RU90395</td>\n",
       "      <td>Cadazolid</td>\n",
       "      <td>Carotegrast methyl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11911</th>\n",
       "      <td>Tolebrutinib</td>\n",
       "      <td>Tirabrutinib</td>\n",
       "      <td>Ibrutinib</td>\n",
       "      <td>Edralbrutinib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11912</th>\n",
       "      <td>Enmetazobactam</td>\n",
       "      <td>2'-O-Methyl-3'-Methyl-3'-Deoxy-Arabinofuranosy...</td>\n",
       "      <td>Deoxyuridine monophosphate</td>\n",
       "      <td>Sulopenem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11913 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 drug                                      alternative_1  \\\n",
       "0         Bivalirudin                                        Semaglutide   \n",
       "1          Leuprolide                                          Buserelin   \n",
       "2           Goserelin                                          Nafarelin   \n",
       "3        Gramicidin D                                             Nerofe   \n",
       "4        Desmopressin                                          Lypressin   \n",
       "...               ...                                                ...   \n",
       "11908        Alogabat  4-(6-CYCLOHEXYLMETHOXY-9H-PURIN-2-YLAMINO)--BE...   \n",
       "11909    Ropsacitinib                                        Regadenoson   \n",
       "11910   taletrectinib                                            RU90395   \n",
       "11911    Tolebrutinib                                       Tirabrutinib   \n",
       "11912  Enmetazobactam  2'-O-Methyl-3'-Methyl-3'-Deoxy-Arabinofuranosy...   \n",
       "\n",
       "                    alternative_2  \\\n",
       "0                       Avexitide   \n",
       "1                      Deslorelin   \n",
       "2                     Triptorelin   \n",
       "3                     Echinomycin   \n",
       "4                     Selepressin   \n",
       "...                           ...   \n",
       "11908                 Mizolastine   \n",
       "11909                 Vistusertib   \n",
       "11910                   Cadazolid   \n",
       "11911                   Ibrutinib   \n",
       "11912  Deoxyuridine monophosphate   \n",
       "\n",
       "                                           alternative_3  \n",
       "0                                PP-F11N lutetium Lu-177  \n",
       "1                                                 Nerofe  \n",
       "2                                              Ganirelix  \n",
       "3                                             Reltecimod  \n",
       "4                                               Ozarelix  \n",
       "...                                                  ...  \n",
       "11908  N-cyclopropyl-4-methyl-3-{2-[(2-morpholin-4-yl...  \n",
       "11909                                      Golidocitinib  \n",
       "11910                                 Carotegrast methyl  \n",
       "11911                                      Edralbrutinib  \n",
       "11912                                          Sulopenem  \n",
       "\n",
       "[11913 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative drugs saved to drug_alternatives.csv\n"
     ]
    }
   ],
   "source": [
    "## Save alternatives to CSV\n",
    "alt_df.to_csv(\"drug_alternatives.csv\", index=False)\n",
    "print(\"Alternative drugs saved to drug_alternatives.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Using BioBert Embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import networkx as nx\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import base64\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse DrugBank XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_drugbank(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    drugs = []\n",
    "    for drug in root.findall(\"{http://www.drugbank.ca}drug\"):\n",
    "        drug_name = drug.find(\"{http://www.drugbank.ca}name\")\n",
    "        drug_id = drug.find(\"{http://www.drugbank.ca}drugbank-id\")\n",
    "        indications = drug.find(\"{http://www.drugbank.ca}indication\")\n",
    "\n",
    "        # Handle missing values safely\n",
    "        drug_name = drug_name.text.strip() if drug_name is not None else \"Unknown\"\n",
    "        drug_id = drug_id.text.strip() if drug_id is not None else \"Unknown\"\n",
    "        indications = indications.text.strip() if (indications is not None and indications.text) else \"No Indications\"\n",
    "\n",
    "        drugs.append({\"Drug\": drug_name, \"DrugID\": drug_id, \"Indications\": indications})\n",
    "    \n",
    "    return pd.DataFrame(drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Drug   DrugID  \\\n",
      "0            Lepirudin  DB00001   \n",
      "1            Cetuximab  DB00002   \n",
      "2         Dornase alfa  DB00003   \n",
      "3  Denileukin diftitox  DB00004   \n",
      "4           Etanercept  DB00005   \n",
      "\n",
      "                                         Indications  \n",
      "0  Lepirudin is indicated for anticoagulation in ...  \n",
      "1  Cetuximab indicated for the treatment of local...  \n",
      "2  Used as adjunct therapy in the treatment of cy...  \n",
      "3         For treatment of cutaneous T-cell lymphoma  \n",
      "4  Etanercept is indicated for the treatment of m...  \n"
     ]
    }
   ],
   "source": [
    "# Parse DrugBank XML and create a DataFrame\n",
    "drug_data = parse_drugbank(\"../Dataset/full database.xml\")\n",
    "print(drug_data.head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BioBERT/SciBERT model for text embeddings on GPU\n",
    "bert_model = SentenceTransformer(\"all-mpnet-base-v2\", device=device)\n",
    "\n",
    "def get_drug_embedding(drug_name, indications):\n",
    "    \"\"\"Generate an embedding for a drug based on its name and indications.\"\"\"\n",
    "    text = f\"{drug_name}: {indications}\"\n",
    "    return bert_model.encode(text, convert_to_numpy=True)\n",
    "\n",
    "# Compute embeddings for all drugs\n",
    "drug_data[\"Embeddings\"] = drug_data.apply(lambda row: get_drug_embedding(row[\"Drug\"], row[\"Indications\"]), axis=1)\n",
    "\n",
    "# Convert embeddings into a NumPy matrix for fast similarity computation\n",
    "embeddings_matrix = np.vstack(drug_data[\"Embeddings\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_similar_drugs_in_rows(top_n=3):\n",
    "    rows = []\n",
    "\n",
    "    for idx, row in drug_data.iterrows():\n",
    "        drug_name = row[\"Drug\"]\n",
    "        target_embedding = row[\"Embeddings\"]\n",
    "\n",
    "        similarities = cosine_similarity([target_embedding], embeddings_matrix)[0]\n",
    "        \n",
    "        temp_df = drug_data.copy()\n",
    "        temp_df[\"Similarity\"] = similarities\n",
    "\n",
    "        # Remove the original drug from candidates\n",
    "        temp_df = temp_df[temp_df[\"Drug\"] != drug_name]\n",
    "\n",
    "        # Get top-N most similar drugs\n",
    "        top_similars = temp_df.sort_values(by=\"Similarity\", ascending=False).head(top_n).reset_index(drop=True)\n",
    "\n",
    "        # Build a single row with the original drug and its top-N alternatives\n",
    "        row_data = {\n",
    "            \"Original Drug\": drug_name,\n",
    "            \"Original Indications\": row[\"Indications\"]\n",
    "        }\n",
    "\n",
    "        for i in range(top_n):\n",
    "            row_data[f\"Alternative {i+1}\"] = top_similars.loc[i, \"Drug\"]\n",
    "            row_data[f\"Similarity {i+1}\"] = round(top_similars.loc[i, \"Similarity\"], 4)\n",
    "            row_data[f\"Indications {i+1}\"] = top_similars.loc[i, \"Indications\"]\n",
    "\n",
    "        rows.append(row_data)\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Drug</th>\n",
       "      <th>Original Indications</th>\n",
       "      <th>Alternative 1</th>\n",
       "      <th>Similarity 1</th>\n",
       "      <th>Indications 1</th>\n",
       "      <th>Alternative 2</th>\n",
       "      <th>Similarity 2</th>\n",
       "      <th>Indications 2</th>\n",
       "      <th>Alternative 3</th>\n",
       "      <th>Similarity 3</th>\n",
       "      <th>Indications 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lepirudin</td>\n",
       "      <td>Lepirudin is indicated for anticoagulation in ...</td>\n",
       "      <td>Dalteparin</td>\n",
       "      <td>0.6823</td>\n",
       "      <td>Dalteparin is used as a prophylaxis for deep-v...</td>\n",
       "      <td>Heparin</td>\n",
       "      <td>0.6634</td>\n",
       "      <td>Unfractionated heparin is indicated for prophy...</td>\n",
       "      <td>Bivalirudin</td>\n",
       "      <td>0.6611</td>\n",
       "      <td>For treatment of heparin-induced thrombocytope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>Cetuximab indicated for the treatment of local...</td>\n",
       "      <td>Cemiplimab</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>Cemiplimab is indicated to treat:\\r\\n\\r\\n- **L...</td>\n",
       "      <td>Ramucirumab</td>\n",
       "      <td>0.7102</td>\n",
       "      <td>Ramucirumab is indicated for the treatment of ...</td>\n",
       "      <td>Cediranib</td>\n",
       "      <td>0.6955</td>\n",
       "      <td>For the treatment of liver cancer, advanced no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dornase alfa</td>\n",
       "      <td>Used as adjunct therapy in the treatment of cy...</td>\n",
       "      <td>Denufosol</td>\n",
       "      <td>0.5917</td>\n",
       "      <td>For use as an inhaled treatment for cystic fib...</td>\n",
       "      <td>Cystic fibrosis transmembrane conductance regu...</td>\n",
       "      <td>0.5874</td>\n",
       "      <td>No Indications</td>\n",
       "      <td>ALTU-135</td>\n",
       "      <td>0.5492</td>\n",
       "      <td>Investigated for use/treatment in cystic fibro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Denileukin diftitox</td>\n",
       "      <td>For treatment of cutaneous T-cell lymphoma</td>\n",
       "      <td>Vorinostat</td>\n",
       "      <td>0.6477</td>\n",
       "      <td>For the treatment of cutaneous manifestations ...</td>\n",
       "      <td>Romidepsin</td>\n",
       "      <td>0.6033</td>\n",
       "      <td>Romidepsin is indicated for the treatment of c...</td>\n",
       "      <td>Brentuximab vedotin</td>\n",
       "      <td>0.5806</td>\n",
       "      <td>Brentuximab vedotin is indicated in adult pati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Etanercept</td>\n",
       "      <td>Etanercept is indicated for the treatment of m...</td>\n",
       "      <td>Etarfolatide</td>\n",
       "      <td>0.6439</td>\n",
       "      <td>No Indications</td>\n",
       "      <td>Abatacept</td>\n",
       "      <td>0.6404</td>\n",
       "      <td>Abatacept is indicated in adult patients for t...</td>\n",
       "      <td>Alefacept</td>\n",
       "      <td>0.6347</td>\n",
       "      <td>As an immunosuppressive drug, Alefacept can be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Original Drug                               Original Indications  \\\n",
       "0            Lepirudin  Lepirudin is indicated for anticoagulation in ...   \n",
       "1            Cetuximab  Cetuximab indicated for the treatment of local...   \n",
       "2         Dornase alfa  Used as adjunct therapy in the treatment of cy...   \n",
       "3  Denileukin diftitox         For treatment of cutaneous T-cell lymphoma   \n",
       "4           Etanercept  Etanercept is indicated for the treatment of m...   \n",
       "\n",
       "  Alternative 1  Similarity 1  \\\n",
       "0    Dalteparin        0.6823   \n",
       "1    Cemiplimab        0.7153   \n",
       "2     Denufosol        0.5917   \n",
       "3    Vorinostat        0.6477   \n",
       "4  Etarfolatide        0.6439   \n",
       "\n",
       "                                       Indications 1  \\\n",
       "0  Dalteparin is used as a prophylaxis for deep-v...   \n",
       "1  Cemiplimab is indicated to treat:\\r\\n\\r\\n- **L...   \n",
       "2  For use as an inhaled treatment for cystic fib...   \n",
       "3  For the treatment of cutaneous manifestations ...   \n",
       "4                                     No Indications   \n",
       "\n",
       "                                       Alternative 2  Similarity 2  \\\n",
       "0                                            Heparin        0.6634   \n",
       "1                                        Ramucirumab        0.7102   \n",
       "2  Cystic fibrosis transmembrane conductance regu...        0.5874   \n",
       "3                                         Romidepsin        0.6033   \n",
       "4                                          Abatacept        0.6404   \n",
       "\n",
       "                                       Indications 2        Alternative 3  \\\n",
       "0  Unfractionated heparin is indicated for prophy...          Bivalirudin   \n",
       "1  Ramucirumab is indicated for the treatment of ...            Cediranib   \n",
       "2                                     No Indications             ALTU-135   \n",
       "3  Romidepsin is indicated for the treatment of c...  Brentuximab vedotin   \n",
       "4  Abatacept is indicated in adult patients for t...            Alefacept   \n",
       "\n",
       "   Similarity 3                                      Indications 3  \n",
       "0        0.6611  For treatment of heparin-induced thrombocytope...  \n",
       "1        0.6955  For the treatment of liver cancer, advanced no...  \n",
       "2        0.5492  Investigated for use/treatment in cystic fibro...  \n",
       "3        0.5806  Brentuximab vedotin is indicated in adult pati...  \n",
       "4        0.6347  As an immunosuppressive drug, Alefacept can be...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structured_alternatives_df = get_top_n_similar_drugs_in_rows(top_n=3)\n",
    "structured_alternatives_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Validation Framework**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import google.generativeai as genai\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query compounds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [01:17<02:01, 40.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving patent IDs for CID 5311128: 504 Server Error: PUGREST.Timeout for url: https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/5311128/xrefs/PatentID/JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [01:48<01:13, 36.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No patents found for Goserelin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [03:01<00:00, 36.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alternative compounds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving patent IDs for CID 91976991: 404 Client Error: PUGREST.NotFound for url: https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/91976991/xrefs/PatentID/JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [06:55<00:00, 83.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining functional similarity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:41<00:00,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total compounds analyzed: 11\n",
      "Functionally similar compounds: 1\n",
      "Average similarity score: 12.27\n",
      "Results saved to validation_results/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class PatentValidationFramework:\n",
    "    def __init__(self, df: pd.DataFrame, api_key: str, query_col: str = \"query\", alternatives_cols: List[str] = None):\n",
    "        \"\"\"\n",
    "        Initialize the framework with a DataFrame containing queries and alternatives.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with drug queries and alternatives\n",
    "            api_key: Google AI API key\n",
    "            query_col: Column name containing the query compound\n",
    "            alternatives_cols: List of column names containing alternative compounds\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.query_col = query_col\n",
    "        self.alternatives_cols = alternatives_cols if alternatives_cols else [col for col in df.columns if col != query_col]\n",
    "        \n",
    "        # Configure Gemini API\n",
    "        genai.configure(api_key=api_key)\n",
    "        \n",
    "        # Select models\n",
    "        self.descriptor_model = genai.GenerativeModel('gemini-2.0-flash-lite')\n",
    "        self.similarity_model = genai.GenerativeModel('gemini-2.0-flash-lite')\n",
    "        \n",
    "        # Results storage\n",
    "        self.patent_data = {}\n",
    "        self.functional_descriptors = {}\n",
    "        self.similarity_results = {}\n",
    "        self.query_results = {}\n",
    "        self.alternative_results = {}\n",
    "        \n",
    "        # API rate limiting\n",
    "        self.pubchem_delay = 0.5  # seconds between PubChem API calls\n",
    "        self.scholar_delay = 2.0  # seconds between Google Scholar requests\n",
    "        self.gemini_delay = 2.5   # seconds between Gemini API calls\n",
    "        \n",
    "    def get_pubchem_cid(self, compound_name: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Convert compound name to PubChem CID.\n",
    "        \n",
    "        Args:\n",
    "            compound_name: Name of the compound\n",
    "            \n",
    "        Returns:\n",
    "            List of PubChem CIDs\n",
    "        \"\"\"\n",
    "        try:\n",
    "            url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/{compound_name}/cids/JSON\"\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if \"IdentifierList\" in data and \"CID\" in data[\"IdentifierList\"]:\n",
    "                return [str(cid) for cid in data[\"IdentifierList\"][\"CID\"]]\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving CID for {compound_name}: {e}\")\n",
    "            return []\n",
    "        finally:\n",
    "            time.sleep(self.pubchem_delay)\n",
    "    \n",
    "    def get_patent_ids(self, cid: str, max_patents: int = 10) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get patent IDs associated with a PubChem CID.\n",
    "        \n",
    "        Args:\n",
    "            cid: PubChem Compound ID\n",
    "            max_patents: Maximum number of patents to retrieve\n",
    "            \n",
    "        Returns:\n",
    "            List of patent IDs\n",
    "        \"\"\"\n",
    "        try:\n",
    "            url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{cid}/xrefs/PatentID/JSON\"\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            \n",
    "            if \"InformationList\" in data and \"Information\" in data[\"InformationList\"]:\n",
    "                info = data[\"InformationList\"][\"Information\"][0]\n",
    "                if \"PatentID\" in info:\n",
    "                    return info[\"PatentID\"][:max_patents]\n",
    "            return []\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving patent IDs for CID {cid}: {e}\")\n",
    "            return []\n",
    "        finally:\n",
    "            time.sleep(self.pubchem_delay)\n",
    "    \n",
    "    def scrape_patent_info(self, patent_id: str) -> Dict[str, str]:\n",
    "        \"\"\"\n",
    "        Scrape patent information from Google Patents.\n",
    "        \n",
    "        Args:\n",
    "            patent_id: Patent identifier\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with patent title, abstract, and description\n",
    "        \"\"\"\n",
    "        try:\n",
    "            patent_id = patent_id.replace(\"-\", \"\")\n",
    "            \n",
    "            url = f\"https://patents.google.com/patent/{patent_id}\"\n",
    "            headers = {\n",
    "                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "            }\n",
    "            response = requests.get(url, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Extract title, abstract, and description\n",
    "            # Actual implementation would need to match Google Patents HTML structure\n",
    "            title_elem = soup.find(\"span\", {\"itemprop\": \"title\"})\n",
    "            title = title_elem.text.strip() if title_elem else \"\"\n",
    "            \n",
    "            abstract_elem = soup.find(\"div\", {\"class\": \"abstract\"})\n",
    "            abstract = abstract_elem.text.strip() if abstract_elem else \"\"\n",
    "            \n",
    "            description_elem = soup.find(\"div\", {\"class\": \"description\"})\n",
    "            description = description_elem.text.strip() if description_elem else \"\"\n",
    "            \n",
    "            return {\n",
    "                \"title\": title,\n",
    "                \"abstract\": abstract,\n",
    "                \"description\": description[:5000]  # Limit description length\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error scraping patent info for {patent_id}: {e}\")\n",
    "            return {\"title\": \"\", \"abstract\": \"\", \"description\": \"\"}\n",
    "        finally:\n",
    "            time.sleep(self.scholar_delay)\n",
    "    \n",
    "    def generate_functional_descriptors(self, patent_info: Dict[str, str], compound_name: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Generate functional descriptors using Gemini.\n",
    "        \n",
    "        Args:\n",
    "            patent_info: Dictionary containing patent title, abstract, and description\n",
    "            compound_name: Name of the compound\n",
    "            \n",
    "        Returns:\n",
    "            List of functional descriptors\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        You are a pharmaceutical expert analyzing patent information for the compound {compound_name}.\n",
    "        \n",
    "        Patent Title: {patent_info['title']}\n",
    "        Patent Abstract: {patent_info['abstract']}\n",
    "        Patent Description: {patent_info['description'][:2000]}...\n",
    "        \n",
    "        Based solely on the patent information above, provide 1-3 brief functional descriptors \n",
    "        (1-3 words each) for the compound {compound_name}. Focus on its therapeutic function, \n",
    "        mechanism of action, or treatment target. Be concise and specific.\n",
    "        \n",
    "        Format your response as a comma-separated list without explanations or additional text.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.descriptor_model.generate_content(prompt)\n",
    "            descriptors_text = response.text.strip()\n",
    "            \n",
    "            # Clean up response to extract just the comma-separated list\n",
    "            cleaned_text = re.sub(r'^[\\s\\S]*?([\\w\\s-]+(?:,\\s*[\\w\\s-]+)*)[\\s\\S]*$', r'\\1', descriptors_text)\n",
    "            descriptors = [d.strip() for d in cleaned_text.split(',')]\n",
    "            \n",
    "            # Clean up descriptors\n",
    "            cleaned_descriptors = []\n",
    "            for d in descriptors:\n",
    "                # Remove any unwanted characters and enforce length limits\n",
    "                d = re.sub(r'[^\\w\\s-]', '', d)\n",
    "                if len(d.split()) <= 3 and d not in cleaned_descriptors:\n",
    "                    cleaned_descriptors.append(d)\n",
    "            \n",
    "            time.sleep(self.gemini_delay)\n",
    "            return cleaned_descriptors\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating descriptors for {compound_name}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def determine_functional_similarity(self, query_descriptors: List[str], \n",
    "                                       alt_descriptors: List[str],\n",
    "                                       query_name: str,\n",
    "                                       alt_name: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Determine functional similarity using Gemini.\n",
    "        \n",
    "        Args:\n",
    "            query_descriptors: List of descriptors for the query compound\n",
    "            alt_descriptors: List of descriptors for the alternative compound\n",
    "            query_name: Name of the query compound\n",
    "            alt_name: Name of the alternative compound\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with similarity assessment\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        You are analyzing the functional similarity between two pharmaceutical compounds:\n",
    "        \n",
    "        Query compound: {query_name}\n",
    "        Functional descriptors: {', '.join(query_descriptors)}\n",
    "        \n",
    "        Alternative compound: {alt_name}\n",
    "        Functional descriptors: {', '.join(alt_descriptors)}\n",
    "        \n",
    "        Based on these functional descriptors, determine whether these compounds have similar functionality.\n",
    "        Consider mechanism of action, therapeutic targets, and clinical applications.\n",
    "        \n",
    "        Provide your assessment as a JSON with the following structure:\n",
    "        {{\n",
    "            \"is_similar\": true/false,\n",
    "            \"similarity_score\": [0-100],\n",
    "            \"explanation\": \"Brief explanation of your reasoning\",\n",
    "            \"shared_functions\": [\"list\", \"of\", \"shared\", \"functions\"]\n",
    "        }}\n",
    "        \n",
    "        Only provide the JSON output, nothing else.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.similarity_model.generate_content(prompt)\n",
    "            similarity_assessment = response.text.strip()\n",
    "            \n",
    "            # Extract the JSON part if there's any text around it\n",
    "            json_match = re.search(r'{.*}', similarity_assessment, re.DOTALL)\n",
    "            if json_match:\n",
    "                similarity_assessment = json_match.group(0)\n",
    "            \n",
    "            # Convert to Python dictionary\n",
    "            try:\n",
    "                result = json.loads(similarity_assessment)\n",
    "                time.sleep(self.gemini_delay)\n",
    "                return result\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"Error parsing JSON from similarity assessment: {similarity_assessment}\")\n",
    "                return {\n",
    "                    \"is_similar\": False,\n",
    "                    \"similarity_score\": 0,\n",
    "                    \"explanation\": \"Error processing response\",\n",
    "                    \"shared_functions\": []\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error determining similarity between {query_name} and {alt_name}: {e}\")\n",
    "            return {\n",
    "                \"is_similar\": False,\n",
    "                \"similarity_score\": 0,\n",
    "                \"explanation\": f\"Error: {str(e)}\",\n",
    "                \"shared_functions\": []\n",
    "            }\n",
    "    \n",
    "    def process_compound(self, compound_name: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Process a single compound through the entire pipeline.\n",
    "        \n",
    "        Args:\n",
    "            compound_name: Name of the compound\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with processing results\n",
    "        \"\"\"\n",
    "        results = {\"name\": compound_name, \"cids\": [], \"patents\": [], \"descriptors\": []}\n",
    "        \n",
    "        # Step 1: Get PubChem CIDs\n",
    "        cids = self.get_pubchem_cid(compound_name)\n",
    "        results[\"cids\"] = cids\n",
    "        \n",
    "        if not cids:\n",
    "            print(f\"No CIDs found for {compound_name}\")\n",
    "            return results\n",
    "        \n",
    "        # Step 2: Get patent IDs (up to 10 per CID)\n",
    "        all_patent_ids = []\n",
    "        for cid in cids[:3]:  # Limit to first 3 CIDs to avoid excessive API calls\n",
    "            patent_ids = self.get_patent_ids(cid)\n",
    "            all_patent_ids.extend(patent_ids)\n",
    "        \n",
    "        # Deduplicate and limit to 10 total\n",
    "        unique_patent_ids = list(set(all_patent_ids))[:10]\n",
    "        results[\"patents\"] = unique_patent_ids\n",
    "        \n",
    "        if not unique_patent_ids:\n",
    "            print(f\"No patents found for {compound_name}\")\n",
    "            return results\n",
    "        \n",
    "        # Step 3: Scrape patent info and generate descriptors\n",
    "        all_descriptors = []\n",
    "        for patent_id in unique_patent_ids[:3]:  # Limit to first 3 patents\n",
    "            patent_info = self.scrape_patent_info(patent_id)\n",
    "            if any(patent_info.values()):  # If we got any useful info\n",
    "                descriptors = self.generate_functional_descriptors(patent_info, compound_name)\n",
    "                all_descriptors.extend(descriptors)\n",
    "        \n",
    "        # Deduplicate descriptors\n",
    "        unique_descriptors = list(set(all_descriptors))\n",
    "        results[\"descriptors\"] = unique_descriptors\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def run_pipeline(self, sample_size: Optional[int] = None) -> Dict:\n",
    "        \"\"\"\n",
    "        Run the full validation pipeline on all compounds in the DataFrame.\n",
    "        \n",
    "        Args:\n",
    "            sample_size: Optional number of rows to process (for testing)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with validation results\n",
    "        \"\"\"\n",
    "        # Process the dataframe\n",
    "        df_to_process = self.df.head(sample_size) if sample_size else self.df\n",
    "        \n",
    "        # Process query compounds\n",
    "        print(\"Processing query compounds...\")\n",
    "        query_results = {}\n",
    "        for idx, row in tqdm(df_to_process.iterrows(), total=len(df_to_process)):\n",
    "            query_name = row[self.query_col]\n",
    "            if query_name not in query_results:\n",
    "                query_results[query_name] = self.process_compound(query_name)\n",
    "        \n",
    "        self.query_results = query_results\n",
    "        \n",
    "        # Process alternative compounds\n",
    "        print(\"Processing alternative compounds...\")\n",
    "        alt_results = {}\n",
    "        for idx, row in tqdm(df_to_process.iterrows(), total=len(df_to_process)):\n",
    "            for alt_col in self.alternatives_cols:\n",
    "                alt_name = row[alt_col]\n",
    "                if pd.notna(alt_name) and alt_name not in alt_results:\n",
    "                    alt_results[alt_name] = self.process_compound(alt_name)\n",
    "        \n",
    "        self.alternative_results = alt_results\n",
    "        \n",
    "        # Determine functional similarity\n",
    "        print(\"Determining functional similarity...\")\n",
    "        similarity_results = []\n",
    "        for idx, row in tqdm(df_to_process.iterrows(), total=len(df_to_process)):\n",
    "            query_name = row[self.query_col]\n",
    "            query_descriptors = query_results.get(query_name, {}).get(\"descriptors\", [])\n",
    "            \n",
    "            for alt_col in self.alternatives_cols:\n",
    "                alt_name = row[alt_col]\n",
    "                if pd.notna(alt_name):\n",
    "                    alt_descriptors = alt_results.get(alt_name, {}).get(\"descriptors\", [])\n",
    "                    \n",
    "                    if query_descriptors and alt_descriptors:\n",
    "                        similarity = self.determine_functional_similarity(\n",
    "                            query_descriptors, alt_descriptors, query_name, alt_name\n",
    "                        )\n",
    "                        \n",
    "                        similarity_results.append({\n",
    "                            \"query\": query_name,\n",
    "                            \"alternative\": alt_name,\n",
    "                            \"is_similar\": similarity.get(\"is_similar\", False),\n",
    "                            \"similarity_score\": similarity.get(\"similarity_score\", 0),\n",
    "                            \"explanation\": similarity.get(\"explanation\", \"\"),\n",
    "                            \"shared_functions\": similarity.get(\"shared_functions\", [])\n",
    "                        })\n",
    "        \n",
    "        self.similarity_results = similarity_results\n",
    "        \n",
    "        # Create a summary DataFrame\n",
    "        summary_df = pd.DataFrame(similarity_results)\n",
    "        \n",
    "        # Return all results\n",
    "        return {\n",
    "            \"query_results\": query_results,\n",
    "            \"alternative_results\": alt_results,\n",
    "            \"similarity_results\": similarity_results,\n",
    "            \"summary_df\": summary_df\n",
    "        }\n",
    "    \n",
    "    def save_results(self, output_dir: str = \"validation_results\"):\n",
    "        \"\"\"Save all results to CSV files.\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Convert nested dictionaries to DataFrames\n",
    "        query_df = pd.DataFrame([\n",
    "            {\"name\": name, \"cids\": \",\".join(data[\"cids\"]), \n",
    "             \"patents\": \",\".join(data[\"patents\"]), \n",
    "             \"descriptors\": \",\".join(data[\"descriptors\"])}\n",
    "            for name, data in self.query_results.items()\n",
    "        ])\n",
    "        \n",
    "        alt_df = pd.DataFrame([\n",
    "            {\"name\": name, \"cids\": \",\".join(data[\"cids\"]), \n",
    "             \"patents\": \",\".join(data[\"patents\"]), \n",
    "             \"descriptors\": \",\".join(data[\"descriptors\"])}\n",
    "            for name, data in self.alternative_results.items()\n",
    "        ])\n",
    "        \n",
    "        sim_df = pd.DataFrame(self.similarity_results)\n",
    "        \n",
    "        # Save to CSV\n",
    "        query_df.to_csv(f\"{output_dir}/query_compounds.csv\", index=False)\n",
    "        alt_df.to_csv(f\"{output_dir}/alternative_compounds.csv\", index=False)\n",
    "        sim_df.to_csv(f\"{output_dir}/similarity_results.csv\", index=False)\n",
    "        \n",
    "        print(f\"Results saved to {output_dir}/\")\n",
    "\n",
    "def main():\n",
    "    GOOGLE_API_KEY = \"AIzaSyAdfhL-mt4l_Yt2Dz5eaWRNfbZcPQxzn6Q\"\n",
    "    \n",
    "    df = alt_df.copy()\n",
    "    \n",
    "    # Initialize validation framework\n",
    "    framework = PatentValidationFramework(df, api_key=GOOGLE_API_KEY, query_col=\"drug\")\n",
    "    \n",
    "    # Run validation pipeline (with a small sample for testing)\n",
    "    results = framework.run_pipeline(sample_size=5)\n",
    "    \n",
    "    # Print summary\n",
    "    summary_df = results[\"summary_df\"]\n",
    "    print(f\"Total compounds analyzed: {len(summary_df)}\")\n",
    "    print(f\"Functionally similar compounds: {summary_df['is_similar'].sum()}\")\n",
    "    print(f\"Average similarity score: {summary_df['similarity_score'].mean():.2f}\")\n",
    "    \n",
    "    # Save results\n",
    "    framework.save_results()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
